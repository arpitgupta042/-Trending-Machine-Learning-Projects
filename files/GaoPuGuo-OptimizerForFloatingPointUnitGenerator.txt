Optimizer for Floating-Point Unit Generator
CS 229 Final Writeup

Jing PU, Mingyu GAO, Tai GUO

1 Introduction
Nowadays digital circuits become more and more complex, and keep requiring higher performance and lower cost. To design a digital circuit, such as a floating-point unit (FPU), usually needs to explore a huge design space to optimize speed, power and area. However, there exists a fundamental tradeoff between these three metrics, and usually people want to find the Pareto optimal configurations called the "design tradeoff curve". Our project focuses on a FPU generator, FPGen [2], which integrates a set of configuration parameters and generates the corresponding FPU circuits. In order to find the Pareto optimal designs, currently FPGen just does brute-force sweeping in the whole design space, which usually contains more than 15 thousands design points. It costs a huge amount of time since evaluating each design point needs hours of synthesis. The goal for our project is to build an optimizer for FPGen using machine learning algorithm to save design time significantly. Here we focus on the delay and energy tradeoff of the circuit. The optimizer is expected to predict the Pareto optimal configurations smartly based on a small set of synthesis data generated by sparse sampling on the design space. The accuracy of this predication should be close to that of the original approach.

2 Data Study and Acquisition
In the design procedure of a digital circuit, the designers need to make decisions on many design choices (which are usually called "features" in the Machine Learning terminology). While some of these features (e.g., the sizes of transistors) can be easily modeled as continuous variables, the others are discrete, including integer variables (e.g., the number of pipeline stages) and categorical variables (e.g., which topology or structure to use). While modern computer-aided design (CAD) tools can optimize many low-level features for us, we still need to make the decision for the high-level integer variables and categorical variables. The fact that the feature space has very high dimension and contains multiple types of components makes the modeling extremely difficult. The features fall into three categories (see Table 1) Device-level features  = (1 , . . . , s ). These features are those that can be handled by the CAD tools. Thus we don't include them in our model, but just leave them to the tools. Circuit-level features  = (1 , . . . , l ). These features can be modeled based on the circuit theory. Architecture-level features  = (1 , . . . , n ). Changing these features often results in totally different structures. So they cannot be covered by the circuit model, and are very difficult to model. For our data acquisition, we used FPGen from Stanford VLSI group [2] for hardware generation and design space exploration. We use 45nm bulk silicon technology from TSMC as our process

1

Category Device-level Circuit-level

Architecture-level

Table 1: Features Name -- FPGen.FMA.PipelineDepth TOP_VT TOP_Voltage FPGen.FMA.EnableMultiplePumping FPGen.FMA.MulShift.MUL0.BoothType FPGen.FMA.MulShift.MUL0.TreeType

Range -- 3,4,5,6,7,8,9,10,12 lvt,svt,hvt 0.8, 0.9, 1 YES,NO 1,2,3,4 Wallace,ZM,OS2,Array

technology for mapping hardware to the physical designs. And then we evaluate the electric characteristics, such as the delay and the power consumption for each physical design using the CAD tool from Synopsys called Design Compiler. In order to gain more confidence in the training and validation phases, we gathered as many data as possible in the limited amount of time. The design space we explored is the cross-product of a set of features. So far, we have obtained more than 15 thousands data points, each of which takes about 20 min  2 hours of CPU time.

3 Model
3.1 Mathematical Abstraction
Given all the design features (, , ), the delay D and the energy E of the circuit are D = D(, , ), E = E(, , ) (1)

Our goal is under a certain requirement of delay D  D, finding the the minimal energy E and the high-level design features (, ) corresponding to it (or vice versa). The device-level features  are left to the design tools. The circuit theory tells us that when  and  are given, there exists trade-off between D and E when we optimize . We model these constraints as E(, , )  f, (D(, , )) (2)

Here f, is a function that is monotonically decreasing. The curve given by f, is often called the Pareto optimal curve, or energy-efficiency curve. Now we can express our optimal problem as min E
,

subject to E  f, (D) DD (3)

We will first model the constraint functions f, and fit them into the training data set, and then do optimization to solve the best design. More details are explained in Section 4.

3.2 Circuit-Level Model
As we said in Section 2, the circuit-level features  can be modeled theoretically based on circuitlevel model. Given a circuit design (, ), the trade-off between D and E by changing , a.k.a, f, , is given by the following model [1] E(, , ) = f, (D(, , )) = K(, ) + E0 (, ) D(, , ) - D0 (, ) (4)

2

where D0 (, ), E0 (, ) and K(, ) are fitting parameters that depends on  and . In our circuit-level model,  = (VDD , THL, p), in which VDD is the supply voltage, THL is the threshold voltage level, and p is the number of pipeline stages. The circuit delay and energy now can be written as the following with respective to these three features explicitly [3] D(, VDD , THL, p, ) = aD () + bD ()p VDD (VDD - VT (THL) - Von )D × d, () p (5)

2 E(, VDD , THL, p, ) = aE () + bE ()p VDD × e, ()

where aD , aE , bD , bE are parameters that depend on the architecture , and D , Von , VT are independent with . d, () and e, () are functions of , modeling the dependency on the device-level features. From (4), we assume that D0  D, E0  E, and K  DE. So the circuit model for these parameters are D0 (, VDD , THL, p) = aD () + bD ()p VDD (VDD - VT (THL) - Von )D p aK () 3 + bK () + cK ()p + dK ()p2 VDD (VDD - VT (THL) - Von )D p (6)

2 Edyn,0 (, VDD , THL, p) = (aE () + bE ()p) VDD

K(, VDD , THL, p) =

Taking (6) into (4), we can represent the model explicitly with  = (VDD , THL, p) and parameters that only depend on .

3.3 Dealing with Architecture-Level Features
Ideally, after Section 3.2, we should continue to model the relationship between the parameters and  explicitly. However, the effects of different  are usually unrelated. For example, using two different topology or algorithm will normally result in totally different performance. Currently no simple and accurate model can describe the effects of the architecture-level parameters. Considering these difficulties, we don't "make up" a model without solid physical explanation, but try to bypass them by utilizing the freedom to control the sparse sampling. We require that the input training set must cover all the architecture-level features so we can learn the parameters depending on  separately. Since the architecture-level feature space is not big, this is not a very strong requirement, and the designer can still reduce a large number of simulations by sampling sparsely in the lower level design spaces of  and .

4 Methodology
Figure 1 shows the methodology we use. Given a small training set from sparse sampling, we first fit (4) to get D0 , E0 and K. Then, considering the difficulties that (6) is non-linear and there are both kinds of parameters that depend and do not depend on , we try to use two-step fitting for the parameters in (6). We first deal with the factor that doesn't depend on  by factorizing the equations and dividing the data from each other. Then we use these results to fit the factor depending on . After that, we calculate D0 (, ), E0 (, ), K(, ) and obtain the Pareto optimal curves f, for all (, ). Finally, we solve the optimization problem (3) by simply picking the minimum E over all (, ), and give the "calculated" optimal D and E. To increase the accuracy, ideally we should feed the calculated optimal configurations back into the synthesis tool and get their actual delays and energy costs. But due to the limited amount of time, another simpler method is used here. Instead of re-synthesizing the calculated configurations, we use (4) to get the "actual" energy E of a certain configuration (, ) under a given D, where the parameters of (4) are learned from the complete data set. We call these result the "predicted" optimal D and E, and treat them as the final output of our model.

3

For each ,  in the input data, fit the equations for 0 ,  , 0 ,  and  , 
Fit  THL and  by cancelling out the parameters depending on 

Fit the circuit model parameters in two sub-steps by factorization

Calculate 0 ,  , 0 ,  and  ,  to predict Energy vs. Delay curve for all valid ,  Solve the optimization problem

Fit the parameters depending on  using the results from step 2a

Figure 1: Methodology

5 Results
5.1 Relative Error of (4)
First of all, we evaluate the accuracy of our simpler method of "back synthesis". The difference between this simpler method and the real synthesis should be evaluated carefully. To do this, we use a relative error calculated as the root mean square (RMS) of the relative difference of E between (4) and the real data = 1 m
m i=1

Ei,pred - Ei,real Ei,real

2

(7)

In our experiments, this value is 0.0158. Thus we conclude that the error of (4) is small enough, and it can be used for our evaluation purpose.

5.2 Errors for Different Training Set Sizes
Our primary purpose is to reduce the number of necessary syntheses to get the Pareto optimal curve. In this section, we evaluate the errors for different input training sets. The error is calculated as the average distance between the real Pareto optimal curve and the predicted optimal curve from our model. In our experiments, we reduce the training set size in different dimensions in the feature space (, , ) and see the different results.

4

15 Unused Samples Used Samples Pareto Optimal Curve Calculated Opt D, E Predicted Opt D, E 10 Energy/pJ 5 1000 2000 3000 4000 5000 6000 7000 Number of Training Samples 8000 9000 10000 0 0

3.8

3.6

Error

3.4

3.2

3

2.8 0.5 1 1.5 Delay/ns 2 2.5 3

(a) Errors for Different Training Set Sizes

(b) An example with 1725 Training Points

Figure 2: Results

4

Figure 2(a) shows the error vs. the training set size. We can see that generally smaller training sets have larger errors. As we use more and more samples, the error will converge to a stable value. However, to our surprise, even some very small training sets are able to predict the Pareto optimal curve with fairly small errors. But the error will vary a lot if we use different training sets. In Section 6, we try to summarize some insights on how to reduce the training set size efficiently. To present an example, we choose a point in Figure 2(a) with 1725 training points and error equal to 3.52, and show the D-E plot in Figure 2(b). The three lines in the figure shows the real Pareto optimal curve (red), the calculated optimal configurations (blue), and the final output predicted optimal configurations from our model (green). The error is the distance between the red line and the green line. We can see that even with this small training set (about 10% of the entire data set), the predicted Pareto optimal curve is very close to the real one, meaning that this is an efficient reduction of the training set size.

6 Discussion
An interesting question to ask is how to choose a efficient reduction of the training set but still keep high accuracy. Here are some guidelines summarized from our experiments: 1. Make sure that the training set covers all . This is because we don't model the architecturelevel features in the model, as stated in Section 3.3. 2. Reduce but keep a certain value (about 3 to 4) for the number of samples with same ,  but different . Also it is better to sample uniformly along the curve, i.e., synthesize designs with very large and very small target delays respectively. This will affect the fitting quality for (4). 3. Reduce but keep a certain value (above 30%) for the percentage of samples that share the same  and cover all the combinations of VDD and THL. This will affect the fitting quality for those parameters in (6) that do not depend on . 4. Reduce but keep a certain value (about 8 to 10) for the number of samples with different pipeline stages p. This will affect the fitting quality for those parameters that depend on .

7 Conclusion
In this project, we characterize the FPU design space and classify the design features into three categories. Using both theoretical and empirical methods, a model is built to capture the effects of different features. The model is quite helpful to reduce the number of necessary syntheses. By applying our model, we are able to predict the Pareto optimal curve with similar accuracy to the original approach, but using only 1/10 of the original data set. That means a saving of 90% circuit synthesis time.

References
[1] O. Azizi, A. Mahesri, J.P. Stevenson, S.J. Patel, and M. Horowitz. An integrated framework for joint design space exploration of microarchitecture and circuits. In Design, Automation Test in Europe Conference Exhibition (DATE), 2010, pages 250­255, 2010. [2] Sameh Galal, Ofer Shacham, John S. Brunhaver II, Jing Pu, Artem Vassiliev, and Mark Horowitz. Fpu generator for design space exploration. Computer Arithmetic, IEEE Symposium on, 0:25­34, 2013. [3] T. Sakurai and A.R. Newton. Alpha-power law mosfet model and its applications to cmos inverter delay and other formulas. Solid-State Circuits, IEEE Journal of, 25(2):584­594, 1990.

5

